{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 3 - Análise de sentimento sobre o mercado financeiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instalação dos pacotes necessários na versão mais nova\n",
    "%pip install -U scikit-learn pandas numpy seaborn spacy --quiet\n",
    "\n",
    "#preparing spacy, hang on we're downloading over 400MB of data :)\n",
    "%pip install \"https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.3.0/en_core_web_lg-3.3.0-py3-none-any.whl\" --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import spacy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.base import TransformerMixin \n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#estimators\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.svm import SVC\n",
    "import lightgbm as lgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # aqui a gente cala a boca do sklearn\n",
    "# # importa o filtro\n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning, UndefinedMetricWarning\n",
    "\n",
    "\n",
    "# # monta o filtro\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "simplefilter(\"ignore\", category=UndefinedMetricWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_classifier_fit_score(cleaner, vectorizer, classifiers: dict, X, y) -> dict:\n",
    "  \"\"\"\n",
    "  Fit and Test multiple classifiers at the same time\n",
    "  Returns a dictonary of scores and a dictionary of all fitted pipelines accessable by the key of the classifiers' dict\n",
    "\n",
    "  Arguments:\n",
    "    cleaner: a pipeline-ready object to clean data\n",
    "    vectorizer: a pipeline-ready object to vectorize the data\n",
    "    classifiers: a dictionary of classifiers to fit and score {'estimator_name': estimator()}\n",
    "    X: features that explain the target\n",
    "    y: target\n",
    "  \n",
    "  Returns:\n",
    "    scores(dict): a dictionary where keys are the classifiers' names inside the classifiers dict and the values are lists\n",
    "      with accuracy, precision and recall scores.\n",
    "    models(dict): a dictionary where the keys are the classifiers' names inside the classifiers dict and the values are \n",
    "      all the models fitted by this function\n",
    "  \"\"\"\n",
    "  from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "  from sklearn.model_selection import train_test_split\n",
    "\n",
    "  scores = {}\n",
    "  models = {}\n",
    "\n",
    "  X_train_mcfs, X_test_mcfs, y_train_mcfs, y_test_mcfs = train_test_split(X, y, test_size=0.3, random_state=10)\n",
    "\n",
    "  for index, classifier in enumerate(classifiers):\n",
    "    classifier_ready = classifiers[classifier]\n",
    "  \n",
    "    pipe_multi_classifier = Pipeline(\n",
    "    steps=[('cleaner', cleaner),\n",
    "          ('vectorizer', vectorizer),\n",
    "          ('classifier', classifier_ready)]\n",
    "    )\n",
    "\n",
    "    pipe_multi_classifier.fit(X_train_mcfs, y_train_mcfs)\n",
    "    \n",
    "    y_pred_mcfs = pipe_multi_classifier.predict(X_test_mcfs)\n",
    "    \n",
    "    scores[classifier] = [\n",
    "      (round(accuracy_score(y_test_mcfs, y_pred_mcfs), 3)), \n",
    "      (round(precision_score(y_test_mcfs, y_pred_mcfs, average='weighted'), 3)), \n",
    "      (round(recall_score(y_test_mcfs, y_pred_mcfs, average='weighted'), 3))\n",
    "    ]\n",
    "\n",
    "    models[classifier] = pipe_multi_classifier\n",
    "  \n",
    "  return scores, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_model(scores: dict, metric: str = 'accuracy') -> list:\n",
    "  \"\"\"\n",
    "  Checks a dictionary of estimators scores and return a list containing the best model\n",
    "  \n",
    "  Arguments:\n",
    "    scores: {'estimator': [accuracy, precision, recall]}\n",
    "    metric: accuracy | precision | recall\n",
    "  \n",
    "  Returns:\n",
    "    list['estimator', 'score', 'metric']\n",
    "  \"\"\"\n",
    "  metrics_dict = {\n",
    "    'accuracy': 0,\n",
    "    'precision': 1,\n",
    "    'recall': 2\n",
    "  }\n",
    "\n",
    "  if metric not in metrics_dict.keys():\n",
    "    metric = 'accuracy'\n",
    "  \n",
    "  position = metrics_dict[metric]\n",
    "  \n",
    "  melhor_modelo = []\n",
    "\n",
    "  for name, score in scores.items():\n",
    "    if len(melhor_modelo) == 0:\n",
    "      melhor_modelo = [name, score[position]]\n",
    "    \n",
    "    if (score[position] >= melhor_modelo[1]):\n",
    "      melhor_modelo = [name, score[position]]\n",
    "  \n",
    "  melhor_modelo.append(metric)\n",
    "  return melhor_modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Construa as funções e a pipeline, separe os dados em treino e teste, execute a pipeline para classificar em positivo, negativo e neutro. Quais foram os valores de acurácia, precisão e sensitividade deste modelo? (3.0 pontos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta funcao remove espacos em branco no inicio e\n",
    "# no fim do texto e converte todo o texto em letras\n",
    "# minusculas\n",
    "def clean_text(texto):     \n",
    "    return texto.strip().lower()\n",
    "\n",
    "# Criamos uma classe para gerenciar X e y\n",
    "class predictors(): #não faz diferença essa herança do TransformerMixin\n",
    "    def transform(self, X, **transform_params):\n",
    "        return [clean_text(text) for text in X]\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    def get_params(self, deep=True):\n",
    "        return {}\n",
    "\n",
    "# Esta funcao remove todas as stopwords e pontuacoes\n",
    "def tokenizer(texto):\n",
    "    doc = nlp(texto)\n",
    "    tokens = [token for token in doc if ((not token.is_stop) & (not token.is_punct))]\n",
    "    tokens = [token.lemma_.lower().strip() for token in tokens]\n",
    "    return tokens\n",
    "\n",
    "# Criamos um objeto CountVectorizer para vetorizar cada\n",
    "# texto\n",
    "vectorizer = CountVectorizer(tokenizer = tokenizer, ngram_range=(1,1), dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The GeoSolutions technology will leverage Bene...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$ESI on lows, down $1.50 to $2.50 BK a real po...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>For the last quarter of 2010 , Componenta 's n...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>According to the Finnish-Russian Chamber of Co...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Swedish buyout firm has sold its remaining...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence Sentiment\n",
       "0  The GeoSolutions technology will leverage Bene...  positive\n",
       "1  $ESI on lows, down $1.50 to $2.50 BK a real po...  negative\n",
       "2  For the last quarter of 2010 , Componenta 's n...  positive\n",
       "3  According to the Finnish-Russian Chamber of Co...   neutral\n",
       "4  The Swedish buyout firm has sold its remaining...   neutral"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financial = pd.read_csv('data.csv')\n",
    "financial.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando em X e y\n",
    "X = financial.Sentence\n",
    "y = financial.Sentiment\n",
    "\n",
    "# Separando em teste e treino\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "              'LGBM': lgb.LGBMClassifier(n_estimators=100), \n",
    "              'SVC': SVC(), \n",
    "              'RandomForest': RandomForestClassifier(), \n",
    "              'AdaBoost': AdaBoostClassifier(DecisionTreeClassifier(), n_estimators=100),\n",
    "              'LogisticRegression': LogisticRegressionCV(cv=5, solver='sag', random_state=42, n_jobs=-1),\n",
    "              'GradientBoosting': GradientBoostingClassifier(random_state=42)\n",
    "              }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LGBM': [0.674, 0.585, 0.553],\n",
       " 'SVC': [0.674, 0.577, 0.514],\n",
       " 'RandomForest': [0.671, 0.559, 0.534],\n",
       " 'AdaBoost': [0.657, 0.56, 0.547],\n",
       " 'LogisticRegression': [0.682, 0.586, 0.561],\n",
       " 'GradientBoosting': [0.693, 0.634, 0.543]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores, models = multi_classifier_fit_score(cleaner= predictors(), vectorizer= vectorizer, classifiers=classifiers, X = financial.Sentence, y = financial.Sentiment)\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GradientBoosting', 0.693, 'accuracy']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melhor_modelo = best_model(scores, metric='accuracy')\n",
    "melhor_modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The best model was GradientBoosting\n",
      "Scoring:\n",
      "Accuracy: 0.693\n",
      "Precision: 0.634\n",
      "Recall: 0.543\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc = scores['GradientBoosting'][0]\n",
    "prec = scores['GradientBoosting'][1]\n",
    "rec = scores['GradientBoosting'][2]\n",
    "\n",
    "print(f'''\n",
    "The best model was {melhor_modelo[0]}\n",
    "Scoring:\n",
    "Accuracy: {acc}\n",
    "Precision: {prec}\n",
    "Recall: {rec}\n",
    "''')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Use o seu modelo para classificar os seguintes textos extraídos do site Financial Times. Faça uma tabela com o valor esperado e o valor obtido, e responda: houve divergência entre o esperado e o obtido? O que poderia ser feito para corrigir? (1.0 ponto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Central banks’ rate rises, geopolitical risk a...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>China opens up bond market in bid to woo forei...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HM Revenue &amp; Customs says residents had £850bn...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Japan’s horrifying crop of data falsification ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Despite internal problems, the group continues...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence Sentiment\n",
       "0  Central banks’ rate rises, geopolitical risk a...  negative\n",
       "1  China opens up bond market in bid to woo forei...   neutral\n",
       "2  HM Revenue & Customs says residents had £850bn...  negative\n",
       "3  Japan’s horrifying crop of data falsification ...  negative\n",
       "4  Despite internal problems, the group continues...   neutral"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data_dict = {\n",
    "                  \"Sentence\": [\"Central banks’ rate rises, geopolitical risk and slowing growth trigger investors’ stampede for safety.\",\n",
    "                          \"China opens up bond market in bid to woo foreign investors.\",\n",
    "                          \"HM Revenue & Customs says residents had £850bn in accounts overseas but it does not estimate if tax paid on this.\",\n",
    "                          \"Japan’s horrifying crop of data falsification is also encouraging. The scandals have emerged from a distinct new phase in the evolution of the country’s shareholder capitalism.\",\n",
    "                          \"Despite internal problems, the group continues to exert a tight grip on the US’s gun control debate.\"],\n",
    "                  \"Sentiment\": [\"negative\", \"neutral\", \"negative\", \"negative\", \"neutral\"]        \n",
    "                          }\n",
    "                          \n",
    "new_data = pd.DataFrame(new_data_dict)\n",
    "\n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;cleaner&#x27;, &lt;__main__.predictors object at 0x7f407e4ab6d0&gt;),\n",
       "                (&#x27;vectorizer&#x27;,\n",
       "                 CountVectorizer(dtype=&lt;class &#x27;numpy.float64&#x27;&gt;,\n",
       "                                 tokenizer=&lt;function tokenizer at 0x7f40a52df010&gt;)),\n",
       "                (&#x27;classifier&#x27;, GradientBoostingClassifier(random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;cleaner&#x27;, &lt;__main__.predictors object at 0x7f407e4ab6d0&gt;),\n",
       "                (&#x27;vectorizer&#x27;,\n",
       "                 CountVectorizer(dtype=&lt;class &#x27;numpy.float64&#x27;&gt;,\n",
       "                                 tokenizer=&lt;function tokenizer at 0x7f40a52df010&gt;)),\n",
       "                (&#x27;classifier&#x27;, GradientBoostingClassifier(random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">predictors</label><div class=\"sk-toggleable__content\"><pre>&lt;__main__.predictors object at 0x7f407e4ab6d0&gt;</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(dtype=&lt;class &#x27;numpy.float64&#x27;&gt;,\n",
       "                tokenizer=&lt;function tokenizer at 0x7f40a52df010&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(random_state=42)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('cleaner', <__main__.predictors object at 0x7f407e4ab6d0>),\n",
       "                ('vectorizer',\n",
       "                 CountVectorizer(dtype=<class 'numpy.float64'>,\n",
       "                                 tokenizer=<function tokenizer at 0x7f40a52df010>)),\n",
       "                ('classifier', GradientBoostingClassifier(random_state=42))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[melhor_modelo[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n",
      "0.167\n",
      "0.333\n"
     ]
    }
   ],
   "source": [
    "y_pred2 = models[melhor_modelo[0]].predict(new_data.Sentence)\n",
    "print(round(accuracy_score(new_data.Sentiment, y_pred2), 3))\n",
    "print(round(precision_score(new_data.Sentiment, y_pred2, average='macro'), 3))\n",
    "print(round(recall_score(new_data.Sentiment, y_pred2, average='macro'), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Original Sentiment</th>\n",
       "      <th>Predicted Sentiment</th>\n",
       "      <th>Divergence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Central banks’ rate rises, geopolitical risk a...</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>China opens up bond market in bid to woo forei...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HM Revenue &amp; Customs says residents had £850bn...</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Japan’s horrifying crop of data falsification ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Despite internal problems, the group continues...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence Original Sentiment  \\\n",
       "0  Central banks’ rate rises, geopolitical risk a...           negative   \n",
       "1  China opens up bond market in bid to woo forei...            neutral   \n",
       "2  HM Revenue & Customs says residents had £850bn...           negative   \n",
       "3  Japan’s horrifying crop of data falsification ...           negative   \n",
       "4  Despite internal problems, the group continues...            neutral   \n",
       "\n",
       "  Predicted Sentiment  Divergence  \n",
       "0            positive        True  \n",
       "1             neutral       False  \n",
       "2             neutral        True  \n",
       "3             neutral        True  \n",
       "4             neutral       False  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = new_data_dict['Sentence']\n",
    "sentiments_or = new_data_dict['Sentiment']\n",
    "sentiments_pred = y_pred2\n",
    "\n",
    "values_dict = {\"Sentence\": sentences, \"Original Sentiment\": sentiments_or, \"Predicted Sentiment\": sentiments_pred}\n",
    "\n",
    "values_df = pd.DataFrame(values_dict)\n",
    "\n",
    "values_df['Divergence'] = values_df[\"Predicted Sentiment\"] != values_df[\"Original Sentiment\"]\n",
    "\n",
    "values_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     3\n",
       "False    2\n",
       "Name: Divergence, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values_df['Divergence'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Faça uma análise exploratória, onde identifique as três empresas mais citadas e quantifique os níveis de positividade, negatividade e neutralidade dos textos sobre estas empresas. (3.0 pontos)\n",
    "\n",
    "##### a. Extraia de todos os textos as entidades, há quantas entidades? (0.6 pontos) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15408"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing\n",
    "\n",
    "entities = 0\n",
    "for row in range(financial.shape[0]):\n",
    "  doc = nlp(financial.Sentence[row])\n",
    "  for ent in doc.ents:\n",
    "    entities += 1\n",
    "\n",
    "entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b. Quantas entidades são empresas? (0.6 pontos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_index</th>\n",
       "      <th>entity</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>GeoSolutions</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Location Based Search Technology</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>ESI</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>BK</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Componenta</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   original_index                            entity sentiment\n",
       "0               0                      GeoSolutions  positive\n",
       "1               0  Location Based Search Technology  positive\n",
       "2               1                               ESI  negative\n",
       "3               1                                BK  negative\n",
       "4               2                        Componenta  positive"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orgs = {'original_index': [], 'entity': [], 'sentiment': []}\n",
    "for row in range(financial.shape[0]):\n",
    "  doc = nlp(financial.Sentence[row])\n",
    "  for ent in doc.ents:\n",
    "    if ent.label_ == 'ORG':\n",
    "      orgs['original_index'].append(row)\n",
    "      orgs['entity'].append(ent.text)\n",
    "      orgs['sentiment'].append(financial.Sentiment[row])\n",
    "\n",
    "ents = pd.DataFrame(orgs)\n",
    "ents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4652,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ents.entity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pretax loss totaled EUR 117mn compared to a loss of EUR 65mn in the corresponding period .'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financial.Sentence[259]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_index</th>\n",
       "      <th>entity</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>33</td>\n",
       "      <td>EUR</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>109</td>\n",
       "      <td>EUR</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>259</td>\n",
       "      <td>EUR</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>440</td>\n",
       "      <td>EUR</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>480</td>\n",
       "      <td>EUR</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>635</td>\n",
       "      <td>EUR</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>653</td>\n",
       "      <td>EUR</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>653</td>\n",
       "      <td>EUR</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>982</td>\n",
       "      <td>EUR</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>1048</td>\n",
       "      <td>EUR</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>1143</td>\n",
       "      <td>EUR</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>1295</td>\n",
       "      <td>EUR</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>1393</td>\n",
       "      <td>EUR</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>1516</td>\n",
       "      <td>EUR</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>1584</td>\n",
       "      <td>EUR</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432</th>\n",
       "      <td>1763</td>\n",
       "      <td>EUR</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>1763</td>\n",
       "      <td>EUR</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1494</th>\n",
       "      <td>1838</td>\n",
       "      <td>EUR</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1506</th>\n",
       "      <td>1852</td>\n",
       "      <td>EUR</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562</th>\n",
       "      <td>1916</td>\n",
       "      <td>EUR</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>1929</td>\n",
       "      <td>EUR</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1622</th>\n",
       "      <td>1992</td>\n",
       "      <td>EUR</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752</th>\n",
       "      <td>2178</td>\n",
       "      <td>EUR</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>2232</td>\n",
       "      <td>EUR</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1817</th>\n",
       "      <td>2253</td>\n",
       "      <td>EUR</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1837</th>\n",
       "      <td>2272</td>\n",
       "      <td>EUR</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962</th>\n",
       "      <td>2450</td>\n",
       "      <td>EUR</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963</th>\n",
       "      <td>2450</td>\n",
       "      <td>EUR</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2093</th>\n",
       "      <td>2609</td>\n",
       "      <td>EUR</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130</th>\n",
       "      <td>2648</td>\n",
       "      <td>EUR</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2299</th>\n",
       "      <td>2850</td>\n",
       "      <td>EUR</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2300</th>\n",
       "      <td>2850</td>\n",
       "      <td>EUR</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2365</th>\n",
       "      <td>2941</td>\n",
       "      <td>EUR</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2401</th>\n",
       "      <td>2982</td>\n",
       "      <td>EUR</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2629</th>\n",
       "      <td>3252</td>\n",
       "      <td>EUR</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2668</th>\n",
       "      <td>3299</td>\n",
       "      <td>EUR</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2716</th>\n",
       "      <td>3365</td>\n",
       "      <td>EUR</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2852</th>\n",
       "      <td>3530</td>\n",
       "      <td>EUR</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2853</th>\n",
       "      <td>3530</td>\n",
       "      <td>EUR</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2900</th>\n",
       "      <td>3579</td>\n",
       "      <td>EUR</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3134</th>\n",
       "      <td>3862</td>\n",
       "      <td>EUR</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3308</th>\n",
       "      <td>4095</td>\n",
       "      <td>EUR</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3309</th>\n",
       "      <td>4095</td>\n",
       "      <td>EUR</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3541</th>\n",
       "      <td>4363</td>\n",
       "      <td>EUR</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3626</th>\n",
       "      <td>4460</td>\n",
       "      <td>EUR</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3711</th>\n",
       "      <td>4570</td>\n",
       "      <td>EUR</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4022</th>\n",
       "      <td>4978</td>\n",
       "      <td>EUR</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4120</th>\n",
       "      <td>5127</td>\n",
       "      <td>EUR</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4159</th>\n",
       "      <td>5185</td>\n",
       "      <td>EUR</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4427</th>\n",
       "      <td>5576</td>\n",
       "      <td>EUR</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4489</th>\n",
       "      <td>5654</td>\n",
       "      <td>EUR</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4497</th>\n",
       "      <td>5661</td>\n",
       "      <td>EUR</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4586</th>\n",
       "      <td>5758</td>\n",
       "      <td>EUR</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4641</th>\n",
       "      <td>5832</td>\n",
       "      <td>EUR</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      original_index entity sentiment\n",
       "26                33    EUR   neutral\n",
       "88               109    EUR   neutral\n",
       "197              259    EUR   neutral\n",
       "364              440    EUR   neutral\n",
       "390              480    EUR  negative\n",
       "515              635    EUR  negative\n",
       "537              653    EUR  positive\n",
       "538              653    EUR  positive\n",
       "817              982    EUR   neutral\n",
       "874             1048    EUR  positive\n",
       "945             1143    EUR  positive\n",
       "1053            1295    EUR  positive\n",
       "1127            1393    EUR  negative\n",
       "1237            1516    EUR  negative\n",
       "1279            1584    EUR  positive\n",
       "1432            1763    EUR   neutral\n",
       "1433            1763    EUR   neutral\n",
       "1494            1838    EUR  positive\n",
       "1506            1852    EUR  positive\n",
       "1562            1916    EUR   neutral\n",
       "1579            1929    EUR   neutral\n",
       "1622            1992    EUR   neutral\n",
       "1752            2178    EUR  negative\n",
       "1795            2232    EUR   neutral\n",
       "1817            2253    EUR   neutral\n",
       "1837            2272    EUR  negative\n",
       "1962            2450    EUR   neutral\n",
       "1963            2450    EUR   neutral\n",
       "2093            2609    EUR   neutral\n",
       "2130            2648    EUR  positive\n",
       "2299            2850    EUR  negative\n",
       "2300            2850    EUR  negative\n",
       "2365            2941    EUR   neutral\n",
       "2401            2982    EUR   neutral\n",
       "2629            3252    EUR   neutral\n",
       "2668            3299    EUR  positive\n",
       "2716            3365    EUR   neutral\n",
       "2852            3530    EUR  negative\n",
       "2853            3530    EUR  negative\n",
       "2900            3579    EUR   neutral\n",
       "3134            3862    EUR  negative\n",
       "3308            4095    EUR  positive\n",
       "3309            4095    EUR  positive\n",
       "3541            4363    EUR   neutral\n",
       "3626            4460    EUR   neutral\n",
       "3711            4570    EUR  positive\n",
       "4022            4978    EUR   neutral\n",
       "4120            5127    EUR  negative\n",
       "4159            5185    EUR  positive\n",
       "4427            5576    EUR   neutral\n",
       "4489            5654    EUR  positive\n",
       "4497            5661    EUR  negative\n",
       "4586            5758    EUR  positive\n",
       "4641            5832    EUR  negative"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ents[ents['entity'] == 'EUR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Nokia                     63\n",
       "EUR                       54\n",
       "AAPL                      40\n",
       "Group                     32\n",
       "Tesco                     29\n",
       "                          ..\n",
       "Hillshire Farms            1\n",
       "ConAgra Names              1\n",
       "Pioneer Library System     1\n",
       "RMG Networks               1\n",
       "Nordic Walking             1\n",
       "Name: entity, Length: 2682, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ents.entity.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c. Quais são as três empresas mais citadas? (0.6 pontos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### d. Faça uma tabela onde demonstre as três empresas mais citadas e o total de textos positivos, negativos e neutros de cada uma. (1.2 pontos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Faça gráficos a partir da tabela obtida acima. Descreva cada gráfico de forma que estivesse apresentando à diretoria dessas três empresas. (3.0 pontos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0c85a8c794e2ef35fe4da22a5230fa839f732614150129be0b83f468abb08431"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.projeto2': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
